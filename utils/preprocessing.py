import pandas as pd
import bibtexparser
from bibtexparser.bibdatabase import BibDatabase
from collections import defaultdict

import os 
import unicodedata

from typing import Optional

current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)
input_dir = os.path.join(root_dir, "doc", "literature_pool", "raw")
output_dir = os.path.join(root_dir, "doc", "literature_pool", "merged")

def xls2bib(file_name: str, sheet_name: Optional[str] = None):
    """
    å°† Excel æ–‡ä»¶è½¬æ¢ä¸º BibTeX æ–‡ä»¶ï¼Œæ ¹æ® Document Type æ˜ å°„ BibTeX ç±»å‹
    """
    def row_to_bibtex(row):
        raw_type = str(row.get('Document Type', '')).strip()
        entrytype = doc_type_mapping.get(raw_type, 'misc')  # é»˜è®¤ misc

        entry = {}
        entry['ENTRYTYPE'] = entrytype
        entry['ID'] = str(row.get('UT (Unique ID)', f"ID{row.name}"))
        entry['author'] = row['Authors'].replace('; ', ' and ') if isinstance(row.get('Authors'), str) else ''
        entry['title'] = row['Article Title'] if isinstance(row.get('Article Title'), str) else ''
        entry['year'] = str(int(row['Publication Year'])) if pd.notnull(row.get('Publication Year')) else ''
        entry['abstract'] = row['Abstract'] if isinstance(row.get('Abstract'), str) else ''

        # æ ¹æ®ç±»å‹è®¾ç½®å‡ºç‰ˆæºå­—æ®µï¼ˆæ›´å®Œæ•´çš„åˆ¤æ–­ï¼‰
        source = row.get('Source Title')
        if isinstance(source, str) and source.strip():
            src = source.strip()
            # å‡†å¤‡ç”¨äºåˆ¤æ–­çš„ entrytypeï¼ˆå°å†™ï¼‰
            et = entrytype.lower()

            # å“ªäº› entry types åº”è¯¥ä½¿ç”¨ booktitle
            booktitle_types = {'inproceedings', 'conference', 'incollection', 'inbook'}

            if et in booktitle_types:
                # ä¼šè®®è®ºæ–‡ / ä¹¦ä¸­ç« èŠ‚ï¼šæŠŠ Source Title å½“ä½œ booktitleï¼ˆæ‰€å±ä¼šè®®æˆ–ä¹¦åï¼‰
                entry['booktitle'] = src
            elif et == 'article':
                # æœŸåˆŠæ–‡ç« ï¼šjournal
                entry['journal'] = src
            elif et == 'proceedings':
                # æ•´ä¸ªè®ºæ–‡é›†ï¼ˆproceedingsï¼‰ï¼šå°† Source Title æ”¾åˆ° titleï¼ˆproceedings çš„ title å­—æ®µï¼‰
                # ä¿ç•™åŸå§‹ titleï¼ˆArticle Titleï¼‰ä¼˜å…ˆï¼Œä¸è¦†ç›–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ Source Title
                if not entry.get('title'):
                    entry['title'] = src
                else:
                    # å¦‚æœå·²ç»æœ‰ titleï¼Œå¯ä»¥æŠŠ proceedings åæ”¾åˆ° noteï¼ˆæˆ– leave outï¼‰
                    entry.setdefault('note', src)
            elif et == 'book':
                # æ•´æœ¬ä¹¦ï¼šé€šå¸¸ Source Title æ˜¯ä¹¦å -> å½“ä½œ titleï¼ˆä»…å½“æ²¡æœ‰ Article Title æ—¶ï¼‰
                if not entry.get('title'):
                    entry['title'] = src
                else:
                    # å¦‚æœ title å·²æœ‰ï¼Œå¯èƒ½ Source Title æ˜¯å‡ºç‰ˆç¤¾æˆ–ä¸¢å¤±ä¿¡æ¯ï¼Œå¯ä»¥æ”¾åˆ° publisher æˆ– note
                    entry.setdefault('publisher', src)
            else:
                # å…¶å®ƒç±»å‹ï¼ˆtechreport, phdthesis, misc ç­‰ï¼‰ï¼Œé»˜è®¤æŠŠ Source Title æ”¾åˆ° noteï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
                entry.setdefault('note', src)

        # å…¶ä»–å¯é€‰å­—æ®µ
        if pd.notnull(row.get('Volume')):
            entry['volume'] = str(int(row['Volume']))
        if pd.notnull(row.get('Issue')):
            entry['number'] = str(int(row['Issue']))
        if pd.notnull(row.get('Start Page')) and pd.notnull(row.get('End Page')):
            entry['pages'] = f"{int(row['Start Page'])}-{int(row['End Page'])}"
        if isinstance(row.get('DOI'), str):
            entry['doi'] = row['DOI']

        return entry


    # è¯»å– Excel æ–‡ä»¶
    input_path =  os.path.join(input_dir, f"{file_name}.xls")
    excel_file = pd.ExcelFile(input_path)
    if sheet_name is None:
        sheet_name = excel_file.sheet_names[0] # type: ignore
    df = pd.read_excel(excel_file, sheet_name=sheet_name)

    # Document Type æ˜ å°„åˆ° BibTeX ç±»å‹
    doc_type_mapping = {
        'Article': 'article',
        'Review': 'article',
        'Proceedings Paper': 'inproceedings',
        'Book Chapter': 'incollection',
        'Book': 'book',
        'Editorial Material': 'misc',
        'Letter': 'misc',
        'Note': 'misc'
    }

    # æ„å»º BibTeX æ•°æ®åº“
    database = BibDatabase()
    for _, row in df.iterrows():
        database.entries.append(row_to_bibtex(row))

    output_path = os.path.join(input_dir, f"{file_name}.bib")
    # å†™å…¥æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as bibtex_file:
        bibtexparser.dump(database, bibtex_file)

    print(f"âœ… BibTeX æ–‡ä»¶å·²ç”Ÿæˆï¼š{output_path}")


def merge_bib(bib_file_list: list[str], output_name: str):
    """
    åˆå¹¶å¤šä¸ª BibTeX æ–‡ä»¶ï¼Œæ ¹æ®æ ‡é¢˜å»é‡ï¼Œä¿ç•™ä¿¡æ¯æœ€å®Œæ•´çš„æ¡ç›®ï¼ˆéç©ºå­—æ®µæœ€å¤šï¼‰
    :param bib_file_list: List[str] å¾…åˆå¹¶çš„ .bib æ–‡ä»¶è·¯å¾„
    :param output_file: str è¾“å‡ºçš„ BibTeX æ–‡ä»¶è·¯å¾„
    """

    removed_count = 0  # æ–°å¢è®¡æ•°å™¨

    def merge_entries(entry_a: dict, entry_b: dict) -> dict:
        """
        å°†ä¸¤ä¸ª BibTeX æ¡ç›®åˆå¹¶ï¼Œå­—æ®µå–å¹¶é›†ã€‚
        è‹¥ä¸¤è€…éƒ½æœ‰è¯¥å­—æ®µï¼Œä¼˜å…ˆé€‰éç©ºçš„ï¼›è‹¥éƒ½éç©ºï¼Œå¯é€‰é•¿åº¦æ›´é•¿çš„ç‰ˆæœ¬ã€‚
        """
        nonlocal removed_count
        removed_count += 1  # æ¯æ¬¡ merge_entries è¢«è°ƒç”¨ï¼Œè¯´æ˜ entry_b è¢«åˆ¤å®šä¸ºé‡å¤

        merged = dict(entry_a)  # å…ˆå¤åˆ¶ç¬¬ä¸€ä¸ª
        for k, v in entry_b.items():
            v = str(v).strip()
            if not v:
                continue
            if k not in merged or not merged[k].strip():
                merged[k] = v
            else:
                # å¦‚æœéƒ½æœ‰å€¼ï¼Œä½†ä¸åŒï¼Œå¯ä»¥é€‰æ›´é•¿çš„é‚£ä¸ªæˆ–ä¿ç•™åŸå€¼
                if merged[k].strip() != v and len(v) > len(merged[k]):
                    merged[k] = v
        return merged

    def normalize_title(title: str) -> str:
        """ç»Ÿä¸€ title æ ¼å¼ï¼Œå»é™¤ç‰¹æ®Šå¼•å·ã€ç©ºæ ¼ã€å¤§å°å†™"""
        if not title:
            return ''
        t = title.lower().strip()
        t = unicodedata.normalize('NFKC', t)
        t = t.replace("â€™", "'").replace("â€˜", "'").replace("â€œ", '"').replace("â€", '"')
        return ''.join(ch for ch in t if ch.isalnum() or ch.isspace())  # å»æ‰æ ‡ç‚¹

    title_dict = {}
    no_title_entries = []

    for bib_file in bib_file_list:
        bib_path = os.path.join(input_dir, bib_file)
        with open(bib_path, 'r', encoding='utf-8', errors='ignore') as f:
            bib_db = bibtexparser.load(f)

        for entry in bib_db.entries:
            title_raw = entry.get('title', '').strip()
            norm_title = normalize_title(title_raw)
            if not norm_title:
                no_title_entries.append(entry)
                continue

            if norm_title in title_dict:
                title_dict[norm_title] = merge_entries(title_dict[norm_title], entry)
            else:
                title_dict[norm_title] = entry

    merged = BibDatabase()
    merged.entries = list(title_dict.values()) + no_title_entries

    merged_database = BibDatabase()
    merged_database.entries = list(title_dict.values()) + no_title_entries

    # å†™å…¥è¾“å‡ºæ–‡ä»¶
    output_path = os.path.join(output_dir, f"{output_name}.bib")
    with open(output_path, 'w', encoding='utf-8') as f:
        bibtexparser.dump(merged_database, f)

    total_entries = len(merged_database.entries)
    print(f"âœ… åˆå¹¶å®Œæˆï¼Œæ€»æ¡ç›®æ•°ï¼š{total_entries}")
    print(f"ğŸ“„ ç§»é™¤/åˆå¹¶é‡å¤æ¡ç›®æ•°ï¼š{removed_count}")
 
def bib2csv(output_name: str):
    """
    å°† BibTeX æ–‡ä»¶å¯¼å…¥åˆ° Excelï¼Œåªä¿ç•™æŒ‡å®šåˆ—ï¼Œå¹¶å¢åŠ ä¸€åˆ—ä¿å­˜åŸå§‹ BibTeX
    """
    output_path = os.path.join(output_dir, f"{output_name}.bib")
    with open(output_path, 'r', encoding='utf-8') as f:
        bib_database = bibtexparser.load(f)

    rows = []
    for entry in bib_database.entries:
        # æ‰‹åŠ¨é‡å»º BibTeX å­—ç¬¦ä¸²
        bibtex_str = f"@{entry.get('ENTRYTYPE', 'misc')}{{{entry.get('ID', '')},\n"
        for key, value in entry.items():
            if key not in ['ENTRYTYPE', 'ID']:
                bibtex_str += f"  {key} = {{{value}}},\n"
        bibtex_str += "}"

        rows.append({
            'Title': entry.get('title', ''),
            'Author': entry.get('author', ''),
            'Year': entry.get('year', ''),
            'DOI': entry.get('doi', ''),
            'Venue': entry.get('journal', entry.get('booktitle', '')),
            'Link': entry.get('url', ''),
            'Publisher': entry.get('publisher', ''),
            'Abstract': entry.get('abstract', ''),
            'BibTeX': bibtex_str  # æ–°å¢è¿™ä¸€åˆ—
        })

    df = pd.DataFrame(rows)
    csv_file_path = os.path.join(output_dir, f"{output_name}.csv")
    df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')

    print(f"âœ… CSV æ–‡ä»¶å·²ç”Ÿæˆï¼š{csv_file_path}")

def preprocess_all(bib_file_name: str, output_name: str):
    xls2bib(bib_file_name)
    bib_files = ["acm.bib", "ieee.bib", "wiley.bib", f"{bib_file_name}.bib"]
    merge_bib(bib_files, output_name)
    bib2csv(output_name)

if __name__ == "__main__":
    input_name = "wos"
    output_name = "remove_duplication"
    preprocess_all(input_name, output_name)
